{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "_kg_hide-output": true,
        "_kg_hide-input": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import os\nimport json\nimport numpy as np\nfrom keras import models\nfrom keras.optimizers import SGD\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.layers.core import Activation, Reshape, Permute\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D\n\nfrom sklearn.model_selection import train_test_split\n\nfrom skimage.io import imread\nfrom skimage.color import rgb2gray",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "9dda7422342117b192e57e04253b906186b7d622"
      },
      "cell_type": "code",
      "source": "img_w = 1280\nimg_h = 1024\nimg_layers = 3\nn_labels = 9\nMASK_COLORS = list(range(n_labels))\nkernel = 3",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "95e1809fbd18609f0bb52e36538b8d487d43b041",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "encoding_layers = [\n    Conv2D(64, kernel, padding='same', input_shape=(img_h, img_w, img_layers)),\n    BatchNormalization(),\n    Activation('relu'),\n    Conv2D(64, kernel, padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n    MaxPooling2D(),\n\n    Conv2D(128, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n    Conv2D(128, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n    MaxPooling2D(),\n\n    Conv2D(256, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n    Conv2D(256, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n    Conv2D(256, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n    MaxPooling2D(),\n\n    Conv2D(512, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n    Conv2D(512, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n    Conv2D(512, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n    MaxPooling2D(),\n\n    Conv2D(512, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n    Conv2D(512, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n    Conv2D(512, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n    MaxPooling2D(),\n]\n\nautoencoder = models.Sequential()\nautoencoder.encoding_layers = encoding_layers\n\nfor l in autoencoder.encoding_layers:\n    autoencoder.add(l)\n    print(l.input_shape, l.output_shape, l)\n\ndecoding_layers = [\n    UpSampling2D(),\n    Conv2D(512, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n    Conv2D(512, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n    Conv2D(512, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n\n    UpSampling2D(),\n    Conv2D(512, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n    Conv2D(512, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n    Conv2D(256, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n\n    UpSampling2D(),\n    Conv2D(256, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n    Conv2D(256, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n    Conv2D(128, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n\n    UpSampling2D(),\n    Conv2D(128, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n    Conv2D(64, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n\n    UpSampling2D(),\n    Conv2D(64, (kernel, kernel), padding='same'),\n    BatchNormalization(),\n    Activation('relu'),\n    Conv2D(n_labels, (1, 1), padding='valid'),\n    BatchNormalization(),\n]\nautoencoder.decoding_layers = decoding_layers\nfor l in autoencoder.decoding_layers:\n    autoencoder.add(l)\n\nautoencoder.add(Reshape((n_labels, img_h * img_w)))\nautoencoder.add(Permute((2, 1)))\nautoencoder.add(Activation('softmax'))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "x_path = \"../input/x/\"\ny_path = \"../input/y/\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1e427c9aa4bdb2c141df655755f4545af7449f90",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def label_map(label):\n    x = np.zeros([*label.shape, n_labels])\n    for i in range(n_labels):\n        x[:,:,i] = label == i\n    return x\n    \n\ndef prep_data():\n    labels = np.array([label_map(imread(y_path + file)[:, :, 0]) for file in os.listdir(y_path)])\n    labels = labels.reshape((len(img), img_h * img_w, n_labels))\n    images = np.array([imread(x_path + file) for file in os.listdir(x_path)]) / 255.\n\n    print('Data prepairing: OK')\n    print('\\tshapes: {}, {}'.format(img.shape, label.shape))\n    print('\\ttypes:  {}, {}'.format(img.dtype, label.dtype))\n    print('\\tmemory: {}, {} MB'.format(img.nbytes / 1048576, label.nbytes / 1048576))\n    \n    return images, labels",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "463116852149e2bd3b7a9aab07dc163408c80fc5",
        "scrolled": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Train model or load weights\nimgs, labels = prep_data()\nX_train, Y_train, X_val, Y_val = train_test_split(imgs, labels, train=0.9)\n\ndata_gen_args = dict(featurewise_center=True,\n                     featurewise_std_normalization=True,\n                     rotation_range=90.,\n                     width_shift_range=0.1,\n                     height_shift_range=0.1,\n                     zoom_range=0.2)\n\nseed = 1\nimage_datagen = ImageDataGenerator(**data_gen_args)\nmask_datagen = ImageDataGenerator(**data_gen_args)\n\nimage_datagen.fit(imgs, augment=True, seed=seed)\nmask_datagen.fit(labels, augment=True, seed=seed)\n\ntrain_images = image_datagen.flow(X_train, y=None, batch_size=32, shuffle=True, sample_weight=None, seed=seed, save_to_dir=None, subset=None)\ntrain_masks = mask_datagen.flow(Y_train, y=None, batch_size=32, shuffle=True, sample_weight=None, seed=seed, save_to_dir=None, subset=None)\nval_images = image_datagen.flow(X_val, y=None, batch_size=32, shuffle=True, sample_weight=None, seed=seed, save_to_dir=None, subset=None)\nval_masks = mask_datagen.flow(Y_val, y=None, batch_size=32, shuffle=True, sample_weight=None, seed=seed, save_to_dir=None, subset=None)\n\ntrain_generator = zip(train_images, train_masks)\nval_generator = zip(val_images, val_masks)\nos.mkdir(\"results\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ef1f26f74fa2e508aadcf2f489fa9d17de43913f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "autoencoder.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\nearly_stop = EarlyStopping(monitor='val_acc', min_delta=0.0001,\n                           patience=5, verbose=1, mode='auto')\ncheckpoint = ModelCheckpoint('results/segnet_best.hdf5',\n                             monitor='val_loss',\n                             verbose=1,\n                             save_best_only=True,\n                             mode='auto')\ncallbacks = [early_stop, checkpoint]\n\nhistory = autoencoder.fit_generator(train_generator, steps_per_epochs=100, epochs=500,\n                                    validation_generator=val_generator, validation_steps,\n                                    verbose=1, callbacks=callbacks)\nautoencoder.save_weights('results/model_segnet_trained.hdf5')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "20f1b18acdb8ce36f2ae1f72b83b9c6b2ec90658"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}